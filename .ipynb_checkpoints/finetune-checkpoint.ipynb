{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0994712",
   "metadata": {},
   "source": [
    "## Try finetuning sLLM step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ffb9e",
   "metadata": {},
   "source": [
    "## Notice! \n",
    "-> if you have some problem with datasets library or transformers library\n",
    "---\n",
    "Problem 1. error \"no module named dataset\" <br>\n",
    "solution 1. !pip3 install datasets<br>\n",
    "---\n",
    "Problem 2. huggingface_hub Error <br>\n",
    "Solution 2. ! pip3 install -U transformers <br>\n",
    "\n",
    "--- \n",
    "are those errors belong GPU session was closed,\n",
    "all the installation information was formatting \n",
    "so, if you restart GPU session, you must reinstall all the library, when install library or file before closed session\n",
    "not Kernel restart only GPU session restart\n",
    "---\n",
    "and also follow this solution\n",
    "1. pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93db206",
   "metadata": {},
   "source": [
    "### Step0. import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9946a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import pipeline\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.optimization import get_scheduler\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989906b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a0ae9",
   "metadata": {},
   "source": [
    "### Step1. CUDA define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3c9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "else:\n",
    "    device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e16cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c09094",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7cc7e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 25 01:08:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  CUDA GPU                       On  | 00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              74W / 300W |   5392MiB / 81074MiB |     N/A      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc6134",
   "metadata": {},
   "source": [
    "### Step2. Data and Model, Tokenizer Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a673cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620ee5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this access token is huggingface's API access KEY if you don't have API key then you must make a KEY first\n",
    "access_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6499cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pretrained model load from huggingface model hub\n",
    "model_name=\"google/gemma-2b-it\"\n",
    "tokenizer_name=\"google/gemma-2b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "916197b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695e9374403f40b8aa3593882f552b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                            token=access_token,\n",
    "                                            device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca7b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## this cell for testing small_dataset training\n",
    "# tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,\n",
    "#                                          token=access_token,\n",
    "#                                          truncation=True,\n",
    "#                                          padding=True,\n",
    "#                                          max_length=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a64db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this cell for training original dataset training\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,\n",
    "                                          token = access_token,\n",
    "                                          truncation=True,\n",
    "                                          padding=True,\n",
    "                                          max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5cc0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d70a1",
   "metadata": {},
   "source": [
    "### Step3. Dataset insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad011b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this DataFrame is not use in this notebooks,\n",
    "## just for show dataset\n",
    "df = pd.DataFrame(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "875994cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create a function to calculate the sum of a se...</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td># Python code\\ndef sum_sequence(sequence):\\n  ...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate a Python code for crawling a website ...</td>\n",
       "      <td>website: www.example.com \\ndata to crawl: phon...</td>\n",
       "      <td>import requests\\nimport re\\n\\ndef crawl_websit...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Create a Python list comprehension to get the ...</td>\n",
       "      <td></td>\n",
       "      <td>[x*x for x in [1, 2, 3, 5, 8, 13]]</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  Create a function to calculate the sum of a se...   \n",
       "1  Generate a Python code for crawling a website ...   \n",
       "2  Create a Python list comprehension to get the ...   \n",
       "\n",
       "                                               input  \\\n",
       "0                                    [1, 2, 3, 4, 5]   \n",
       "1  website: www.example.com \\ndata to crawl: phon...   \n",
       "2                                                      \n",
       "\n",
       "                                              output  \\\n",
       "0  # Python code\\ndef sum_sequence(sequence):\\n  ...   \n",
       "1  import requests\\nimport re\\n\\ndef crawl_websit...   \n",
       "2                 [x*x for x in [1, 2, 3, 5, 8, 13]]   \n",
       "\n",
       "                                              prompt  \n",
       "0  Below is an instruction that describes a task....  \n",
       "1  Below is an instruction that describes a task....  \n",
       "2  Below is an instruction that describes a task....  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd79ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for NatureLanguage To Tokenized Language\n",
    "def tokenize_function(row):\n",
    "    return tokenizer(row[\"instruction\"],row[\"output\"],row[\"input\"],row[\"prompt\"], padding=True,truncation=True,max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84b441fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4f02a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12c98c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>prompt</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create a function to calculate the sum of a se...</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td># Python code\\ndef sum_sequence(sequence):\\n  ...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generate a Python code for crawling a website ...</td>\n",
       "      <td>website: www.example.com \\ndata to crawl: phon...</td>\n",
       "      <td>import requests\\nimport re\\n\\ndef crawl_websit...</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 33480, 235292, 5266, 235265, 7310, 235265,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Create a Python list comprehension to get the ...</td>\n",
       "      <td></td>\n",
       "      <td>[x*x for x in [1, 2, 3, 5, 8, 13]]</td>\n",
       "      <td>Below is an instruction that describes a task....</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0  Create a function to calculate the sum of a se...   \n",
       "1  Generate a Python code for crawling a website ...   \n",
       "2  Create a Python list comprehension to get the ...   \n",
       "\n",
       "                                               input  \\\n",
       "0                                    [1, 2, 3, 4, 5]   \n",
       "1  website: www.example.com \\ndata to crawl: phon...   \n",
       "2                                                      \n",
       "\n",
       "                                              output  \\\n",
       "0  # Python code\\ndef sum_sequence(sequence):\\n  ...   \n",
       "1  import requests\\nimport re\\n\\ndef crawl_websit...   \n",
       "2                 [x*x for x in [1, 2, 3, 5, 8, 13]]   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Below is an instruction that describes a task....   \n",
       "1  Below is an instruction that describes a task....   \n",
       "2  Below is an instruction that describes a task....   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [2, 33480, 235292, 5266, 235265, 7310, 235265,...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a997b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenized dataset split\n",
    "tokenized_dataset = tokenized_datasets.train_test_split(test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155c37e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c080be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## this cell for testing small_dataset\n",
    "# small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=41).select(range(1000))\n",
    "# small_test_dataset = tokenized_dataset[\"test\"].shuffle(seed=41).select(range(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9cb1bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_dataset[\"train\"].shuffle(seed=7)\n",
    "test_dataset = tokenized_dataset[\"test\"].shuffle(seed=7).select(range(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29125b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # small_dataset \n",
    "# small_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b718ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # small_dataset\n",
    "# small_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc850b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e420302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a5a5b",
   "metadata": {},
   "source": [
    "### Step4. Config Method and Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fc0b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6227d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    #logits, labels = eval_pred\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    labels = eval_pred.labels\n",
    "    \n",
    "    eval_dict = {'predictions':predictions,'references':labels}\n",
    "    return metric.compute(**eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd06dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22794ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this cell for testing small-dataset\n",
    "# training_args = TrainingArguments(output_dir=\"./finetune_results\",\n",
    "#                                   num_train_epochs=4,\n",
    "#                                  per_device_train_batch_size=1,\n",
    "#                                  per_device_eval_batch_size=1,\n",
    "#                                  gradient_accumulation_steps=4,\n",
    "#                                 logging_steps=10,\n",
    "#                                   learning_rate=2e-3,\n",
    "#                                   eval_accumulation_steps=8\n",
    "#                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff4eb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./finetune_results_2\",\n",
    "                                 num_train_epochs=3,\n",
    "                                 per_device_train_batch_size=2,\n",
    "                                 per_device_eval_batch_size=2, \n",
    "                                 gradient_accumulation_steps=4,\n",
    "                                  eval_accumulation_steps=10,\n",
    "                                 logging_steps=10,\n",
    "                                 learning_rate=2e-5, \n",
    "                                 warmup_steps=100,\n",
    "                                 weight_decay=0.01,\n",
    "                                 logging_dir=\"./finetune_logs_2\",\n",
    "                                 do_eval=True,\n",
    "                                  eval_steps=100,\n",
    "                                  save_steps=100,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",\n",
    "                                 load_best_model_at_end=True,\n",
    "                                 dataloader_num_workers=multiprocessing.cpu_count(),\n",
    "                                 optim=\"adamw_torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f834b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this cell for testing small dataset\n",
    "# trainer = Trainer(model=model,\n",
    "#                  args=training_args,\n",
    "#                  train_dataset=small_train_dataset,\n",
    "#                  eval_dataset=small_test_dataset,\n",
    "#                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e468ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                 args=training_args,\n",
    "                 train_dataset=train_dataset,\n",
    "                 eval_dataset=test_dataset,\n",
    "                 compute_metrics=compute_metrics,\n",
    "                 callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.01)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e39a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrlfdnjs9839\u001b[0m (\u001b[33mlineworld\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/sLLM/wandb/run-20240425_010919-3o58irq9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/lineworld/huggingface/runs/3o58irq9\" target=\"_blank\">fallen-star-73</a></strong> to <a href=\"https://wandb.ai/lineworld/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='754' max='4884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 754/4884 07:05 < 38:56, 1.77 it/s, Epoch 0.46/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e12ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cfd793",
   "metadata": {},
   "source": [
    "### Step5. Save a fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89144a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_name=\"line_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(new_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad270c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub(new_model_name, use_temp_dir=False)\n",
    "# tokenizer.push_to_hub(new_model_name, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e50b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0 (NGC 23.03/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
