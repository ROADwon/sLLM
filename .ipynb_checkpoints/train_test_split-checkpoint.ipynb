{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2433f72",
   "metadata": {},
   "source": [
    "## dataset train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf15fb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed2eac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc42064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 freeze | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01f366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d17e2a",
   "metadata": {},
   "source": [
    "## Notice! \n",
    "-> if you have some problem with datasets library or transformers library\n",
    "---\n",
    "Problem 1. error \"no module named dataset\" <br>\n",
    "solution 1. !pip3 install datasets<br>\n",
    "---\n",
    "Problem 2. huggingface_hub Error <br>\n",
    "Solution 2. ! pip3 install -U transformers <br>\n",
    "\n",
    "--- \n",
    "are those errors belong GPU session was closed,\n",
    "all the installation information was formatting \n",
    "so, if you restart GPU session, you must reinstall all the library, when install library or file before closed session\n",
    "not Kernel restart only GPU session restart\n",
    "---\n",
    "and also follow this solution\n",
    "1. pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388acc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze >> requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "277ffcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d587c",
   "metadata": {},
   "source": [
    "### before Starting make a simple function \n",
    "#### this function use for working clock to parameter value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637ca1d",
   "metadata": {},
   "source": [
    "## Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc34085",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0515bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"iamtarun/python_code_instructions_18k_alpaca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59cc0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "347362fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer_name = \"google/gemma-2b-it\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589cfa62",
   "metadata": {},
   "source": [
    "## Checking Datasets Type and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4045f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 18612\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0230025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18612, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4dc0b8",
   "metadata": {},
   "source": [
    "### using dataset's train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f9baf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820027e1",
   "metadata": {},
   "source": [
    "## using sklearn.model_selection's train_test_split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3bed08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7ce1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sklearn = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a7cfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 18612\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d288d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(ds_sklearn[\"train\"], test_size=.3, random_state=1832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5214cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c0cd74",
   "metadata": {},
   "source": [
    "## model & tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e68c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f2fae4b76d4820a3aa8507b060023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                          token=access_token,\n",
    "                                          device_map=\"auto\",\n",
    "                                           torch_dtype=torch.float32,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1296a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,\n",
    "                                         token=access_token,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30933183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 21 10:24:51 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  CUDA GPU                       On  | 00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   45C    P0              74W / 300W |  10024MiB / 81074MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87561a",
   "metadata": {},
   "source": [
    "## processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff11f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d37a96d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "652f7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b9db7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "912913fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ds[\"test\"]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2efc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    return tokenizer(row[\"instruction\"],row[\"input\"],row[\"output\"],row[\"prompt\"], return_tensors=\"pt\", truncation=True, padding=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09c1d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee466055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc2a7cb4a1445459fcda2d896616d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/13028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21898d68a8fc43ebadb62a08cfd83dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(process,\n",
    "           num_proc = multiprocessing.cpu_count(),\n",
    "           load_from_cache_file=False,\n",
    "           batched=True)\n",
    "train_dataset = ds[\"train\"]\n",
    "test_dataset = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "148baa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8149d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a831642",
   "metadata": {},
   "source": [
    "## model & Trainer arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f2276fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0903a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./eval_log_3\",\n",
    "                                 num_train_epochs=3,\n",
    "                                 per_device_train_batch_size=4,\n",
    "                                 per_device_eval_batch_size=4,\n",
    "                                 weight_decay=0.01,\n",
    "                                 logging_dir=\"./eval_logs_3\",\n",
    "                                 logging_steps=300,\n",
    "                                 warmup_steps=500,\n",
    "                                 dataloader_num_workers=2,\n",
    "                                 eval_accumulation_steps=1,\n",
    "                                 gradient_accumulation_steps=2,\n",
    "                                 optim=\"adamw_torch\",\n",
    "                                 evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07220f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc1c223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f49ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metrix = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "735bc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(eval_pred):\n",
    "    logit, labels =eval_pred\n",
    "    predict = np.argmax(logit, axis=-1)\n",
    "    return acc_metrix.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f215ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(model,\n",
    "                       args=training_args,\n",
    "                       train_dataset=train_dataset,\n",
    "                       eval_dataset=test_dataset,\n",
    "                       tokenizer=tokenizer,\n",
    "                       compute_metrics=compute_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrlfdnjs9839\u001b[0m (\u001b[33mlineworld\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/sLLM/wandb/run-20240421_102511-19j5lxdv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/lineworld/huggingface/runs/19j5lxdv\" target=\"_blank\">earnest-river-39</a></strong> to <a href=\"https://wandb.ai/lineworld/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='385' max='4884' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 385/4884 02:27 < 28:58, 2.59 it/s, Epoch 0.24/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbaf9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01bbac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0 (NGC 23.03/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
