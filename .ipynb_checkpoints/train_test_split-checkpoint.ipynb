{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bc4146",
   "metadata": {},
   "source": [
    "## dataset train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75bde6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e7224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12660663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 freeze | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bd7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a0d836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3af37",
   "metadata": {},
   "source": [
    "## Notice! \n",
    "-> if you have some problem with datasets library or transformers library\n",
    "---\n",
    "Problem 1. error \"no module named dataset\" <br>\n",
    "solution 1. !pip3 install datasets<br>\n",
    "---\n",
    "Problem 2. huggingface_hub Error <br>\n",
    "Solution 2. ! pip3 install -U transformers <br>\n",
    "\n",
    "--- \n",
    "are those errors belong GPU session was closed,\n",
    "all the installation information was formatting \n",
    "so, if you restart GPU session, you must reinstall all the library, when install library or file before closed session\n",
    "not Kernel restart only GPU session restart\n",
    "---\n",
    "and also follow this solution\n",
    "1. pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93efb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze >> requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1cda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045d7db",
   "metadata": {},
   "source": [
    "### before Starting make a simple function \n",
    "#### this function use for working clock to parameter value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e854cbf",
   "metadata": {},
   "source": [
    "## CUDA load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf7658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839eb4a",
   "metadata": {},
   "source": [
    "## Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ffb531",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce64ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"iamtarun/python_code_instructions_18k_alpaca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93edc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efd63c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer_name = \"google/gemma-2b-it\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba72cc1",
   "metadata": {},
   "source": [
    "## Checking Datasets Type and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08e86cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 18612\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de6203ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18612, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b7729",
   "metadata": {},
   "source": [
    "### using dataset's train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d859a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d38d1b",
   "metadata": {},
   "source": [
    "## using sklearn.model_selection's train_test_split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bdf5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d904250",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sklearn = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "998113d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 18612\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c45bd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(ds_sklearn[\"train\"], test_size=.3, random_state=1832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e571472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd61a80",
   "metadata": {},
   "source": [
    "## model & tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25af9c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc228e8fd434a92a7c0cf2a9a3f9b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                          token=access_token,\n",
    "                                          device_map=\"auto\",\n",
    "                                           torch_dtype=torch.float32,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d17722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,\n",
    "                                         token=access_token,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         max_length=100,\n",
    "                                         )\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5efbb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 22 07:07:39 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  CUDA GPU                       On  | 00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   44C    P0              73W / 300W |  10024MiB / 81074MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66344741",
   "metadata": {},
   "source": [
    "## processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2109571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e69e3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ccabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55a90290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8cae28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ds[\"test\"]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "821635d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    return tokenizer(row[\"instruction\"],row[\"input\"],row[\"output\"],row[\"prompt\"], return_tensors=\"pt\", truncation=True, padding=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8662c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d90d1682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cf1dba28414bf1bb13aaa292d06e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/13028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583b1ac78af74477bade104bfada6199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(process,\n",
    "           num_proc = multiprocessing.cpu_count(),\n",
    "           load_from_cache_file=False,\n",
    "           batched=True)\n",
    "train_dataset = ds[\"train\"]\n",
    "test_dataset = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "471676ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9881f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c234378",
   "metadata": {},
   "source": [
    "## model & Trainer arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a77f7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3503e8e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "--load_best_model_at_end requires the saving steps to be a round multiple of the evaluation steps, but found 500, which is not a round multiple of 600.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./eval_results_4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./eval_logs_4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdataloader_num_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43meval_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madamw_torch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdo_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:125\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/training_args.py:1519\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_steps \u001b[38;5;241m*\u001b[39m LARGE_MULTIPLIER) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_steps \u001b[38;5;241m*\u001b[39m LARGE_MULTIPLIER) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1515\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1516\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--load_best_model_at_end requires the saving steps to be a multiple of the evaluation \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1517\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is not a multiple of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1518\u001b[0m                 )\n\u001b[0;32m-> 1519\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1520\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--load_best_model_at_end requires the saving steps to be a round multiple of the evaluation \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1521\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is not a round multiple of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1522\u001b[0m         )\n\u001b[1;32m   1524\u001b[0m safetensors_available \u001b[38;5;241m=\u001b[39m is_safetensors_available()\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_safetensors \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safetensors_available:\n",
      "\u001b[0;31mValueError\u001b[0m: --load_best_model_at_end requires the saving steps to be a round multiple of the evaluation steps, but found 500, which is not a round multiple of 600."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./eval_results_4\",\n",
    "                                 num_train_epochs=3,\n",
    "                                 per_device_train_batch_size=2,\n",
    "                                 per_device_eval_batch_size=2,\n",
    "                                 weight_decay=0.01,\n",
    "                                 logging_dir=\"./eval_logs_4\",\n",
    "                                 logging_steps=500,\n",
    "                                 warmup_steps=300,\n",
    "                                 dataloader_num_workers=4,\n",
    "                                 eval_accumulation_steps=1,\n",
    "                                 gradient_accumulation_steps=2,\n",
    "                                 optim=\"adamw_torch\",\n",
    "                                 evaluation_strategy=\"steps\",\n",
    "                                 save_strategy=\"steps\",\n",
    "                                 do_eval=True,\n",
    "                                 load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fbc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ab6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metrix = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c54d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(eval_pred):\n",
    "    logit, labels =eval_pred\n",
    "    predict = np.argmax(logit, axis=-1)\n",
    "    return acc_metrix.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(model,\n",
    "                       args=training_args,\n",
    "                       train_dataset=train_dataset,\n",
    "                       eval_dataset=test_dataset,\n",
    "                       tokenizer=tokenizer,\n",
    "                       compute_metrics=compute_matrix,\n",
    "#                        callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b26019",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b04c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6741dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0 (NGC 23.03/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
