{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d3b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install peft trl wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f952cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11fd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --force-reinstall typing-extensions==4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d481d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83bc47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec47396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a7ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38edbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d835c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip freeze | grep flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab24a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212113bd",
   "metadata": {},
   "source": [
    "## dataset train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682b5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import pipeline\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import ORPOConfig, ORPOTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c899aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf64a92",
   "metadata": {},
   "source": [
    "## Notice! \n",
    "-> if you have some problem with datasets library or transformers library\n",
    "---\n",
    "Problem 1. error \"no module named dataset\" <br>\n",
    "solution 1. !pip3 install datasets<br>\n",
    "---\n",
    "Problem 2. huggingface_hub Error <br>\n",
    "Solution 2. ! pip3 install -U transformers <br>\n",
    "\n",
    "--- \n",
    "are those errors belong GPU session was closed,\n",
    "all the installation information was formatting \n",
    "so, if you restart GPU session, you must reinstall all the library, when install library or file before closed session\n",
    "not Kernel restart only GPU session restart\n",
    "---\n",
    "and also follow this solution\n",
    "1. pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c026d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze >> requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a06c1",
   "metadata": {},
   "source": [
    "### before Starting make a simple function \n",
    "#### this function use for working clock to parameter value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c4cb2",
   "metadata": {},
   "source": [
    "## CUDA load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7db44ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8da03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_implementation = \"eager\"\n",
    "torch_dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "161f88d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eager'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "257f64d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75f097",
   "metadata": {},
   "source": [
    "## Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c18a93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6561d9d6c7471dab542c56902ef0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7480316d6fb640aca3ed99dac5f013ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854738d4e73b455898677ff9dbaefc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18612 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d5135d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"iamtarun/python_code_instructions_18k_alpaca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7b40a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d562c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer_name = \"google/gemma-2b-it\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342fc7b",
   "metadata": {},
   "source": [
    "## Checking Datasets Type and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4904cdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 18612\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8ba7018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18612, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf73409",
   "metadata": {},
   "source": [
    "### using dataset's train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f20f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6552d80",
   "metadata": {},
   "source": [
    "## using sklearn.model_selection's train_test_split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4433e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "153669c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_sklearn = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a14e2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3767bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = train_test_split(ds_sklearn[\"train\"], test_size=.3, random_state=1832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b745b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb88f43",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c1de556",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config=BitsAndBytesConfig(load_in_4bit=True,\n",
    "                             bnb_4bit_quant_type=\"nf4\",\n",
    "                             bnb_4bit_compute_dtype=torch_dtype,\n",
    "                             bnb_4bit_use_double_quant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44a287c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(r=16,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=.05,\n",
    "                        bias=\"none\",\n",
    "                        task_type=\"CAUSAL_LM\",\n",
    "                        target_modules=[\"up_proj\",\"donw_proj\",\"gate_proj\",\"k_proj\",\n",
    "                                       \"q_proj\",\"v_proj\",\"o_proj\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73d458",
   "metadata": {},
   "source": [
    "## model & tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ebdbd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de49e161e4f84b51aacea90ca54b6778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8d15db38624905853733e12430b7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde4f43bf4a249119a2178b75f2dc0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1176250fd6a4c329ae36bdc32768569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299afe1603d244bea33b4691ef5622f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3e0b8544364e328629815ee26d75b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6f3090596a4fc78870c2baff40ce00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                          token=access_token,\n",
    "                                          device_map=\"auto\",\n",
    "                                            attn_implementation=attn_implementation,\n",
    "                                           quantization_config=bnb_config\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1878171c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35da200ca045442e8ed64b9eff2d375b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1b786fcdb54841876ec9de99e366ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedd80eb509c4587aa45c2982209ea79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed58b27308fa4d5e96becc7e916ecdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,\n",
    "                                         token=access_token,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         max_length=100,\n",
    "                                         )\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23a3b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d07b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "356397ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 23 04:16:02 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  CUDA GPU                       On  | 00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              72W / 300W |   5522MiB / 81074MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4577c2c",
   "metadata": {},
   "source": [
    "## processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee7f4423",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'train_test_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.3\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'train_test_split'"
     ]
    }
   ],
   "source": [
    "ds = ds.train_test_split(test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee10340",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2552db15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f93ec55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "678ba5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ds[\"test\"]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f03ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    return tokenizer(row[\"instruction\"],row[\"input\"],row[\"output\"],row[\"prompt\"], return_tensors=\"pt\", truncation=True, padding=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48166073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de1bc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ee4ea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b1e65203ec4f52b02adea676ced8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/13028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a02f8e97de435290cbf0b279a57e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(process,\n",
    "           num_proc = multiprocessing.cpu_count(),\n",
    "           load_from_cache_file=False,\n",
    "           batched=True)\n",
    "train_dataset = ds[\"train\"]\n",
    "test_dataset = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4bfbefce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "937209d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb75b4e",
   "metadata": {},
   "source": [
    "## model & Trainer arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a19495",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ae1c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = ORPOConfig(output_dir=\"./eval_results_5\",\n",
    "#                                  num_train_epochs=3,\n",
    "#                                  per_device_train_batch_size=2,\n",
    "#                                  per_device_eval_batch_size=2,\n",
    "#                                  weight_decay=0.01,\n",
    "#                                  logging_dir=\"./eval_logs_5\",\n",
    "#                                  logging_steps=1,\n",
    "#                                   eval_steps=0.2,\n",
    "#                                  warmup_steps=10,\n",
    "#                                   learning_rate=8e-6,\n",
    "#                                   beta=0.1,\n",
    "#                                  dataloader_num_workers=4,\n",
    "#                                  eval_accumulation_steps=1,\n",
    "#                                  gradient_accumulation_steps=2,\n",
    "#                                  optim=\"adamw_torch\",\n",
    "#                                  evaluation_strategy=\"steps\",\n",
    "#                                  save_strategy=\"steps\",\n",
    "#                                  do_eval=True,\n",
    "#                                  load_best_model_at_end=True,\n",
    "#                                  max_length=1024,\n",
    "#                                   max_prompt_length=512,\n",
    "#                                  lr_scheduler_type='linear')\n",
    "orpo_args = ORPOConfig(\n",
    "    learning_rate=8e-6,\n",
    "    beta=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    max_length=1024,\n",
    "    max_prompt_length=512,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    report_to=\"wandb\",\n",
    "    output_dir=\"./results/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c92b4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.8/site-packages/trl/trainer/orpo_trainer.py:247: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6d9b616d10482ba79ba94f5e5b364a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'chosen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mORPOTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morpo_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trl/trainer/orpo_trainer.py:276\u001b[0m, in \u001b[0;36mORPOTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, compute_metrics)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Compute that only on the main process for faster data processing.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# see: https://github.com/huggingface/trl/pull/1255\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PartialState()\u001b[38;5;241m.\u001b[39mlocal_main_process_first():\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# tokenize the dataset\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_num_proc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m         eval_dataset \u001b[38;5;241m=\u001b[39m eval_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize_row, num_proc\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdataset_num_proc)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3157\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3158\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:3517\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3515\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3517\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3519\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3420\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/trl/trainer/orpo_trainer.py:397\u001b[0m, in \u001b[0;36mORPOTrainer.tokenize_row\u001b[0;34m(self, feature, model)\u001b[0m\n\u001b[1;32m    395\u001b[0m batch \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    396\u001b[0m prompt \u001b[38;5;241m=\u001b[39m feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 397\u001b[0m chosen \u001b[38;5;241m=\u001b[39m \u001b[43mfeature\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchosen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    398\u001b[0m rejected \u001b[38;5;241m=\u001b[39m feature[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrejected\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Check issues below for more details\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m#  1. https://github.com/huggingface/trl/issues/907\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m#  2. https://github.com/EleutherAI/lm-evaluation-harness/pull/531#issuecomment-1595586257\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m#  3. https://github.com/LianjiaTech/BELLE/issues/337\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/formatting/formatting.py:271\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 271\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[1;32m    273\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'chosen'"
     ]
    }
   ],
   "source": [
    "trainer = ORPOTrainer(model=model,\n",
    "                     args=orpo_args,\n",
    "                     train_dataset=train_dataset,\n",
    "                     eval_dataset=test_dataset,\n",
    "                     peft_config=peft_config,\n",
    "                     tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a02c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f16532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc148828",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metrix = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(eval_pred):\n",
    "    logit, labels =eval_pred\n",
    "    predict = np.argmax(logit, axis=-1)\n",
    "    return acc_metrix.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(model,\n",
    "                       args=training_args,\n",
    "                       train_dataset=train_dataset,\n",
    "                       eval_dataset=test_dataset,\n",
    "                       tokenizer=tokenizer,\n",
    "                       compute_metrics=compute_matrix,\n",
    "#                        callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146932cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be4937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0 (NGC 23.03/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
