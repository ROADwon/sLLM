{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f38342",
   "metadata": {},
   "source": [
    "## dataset train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe5d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c28817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74fb1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 freeze | grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb3e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a97fb70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0d951",
   "metadata": {},
   "source": [
    "## Notice! \n",
    "-> if you have some problem with datasets library or transformers library\n",
    "---\n",
    "Problem 1. error \"no module named dataset\" <br>\n",
    "solution 1. !pip3 install datasets<br>\n",
    "---\n",
    "Problem 2. huggingface_hub Error <br>\n",
    "Solution 2. ! pip3 install -U transformers <br>\n",
    "\n",
    "--- \n",
    "are those errors belong GPU session was closed,\n",
    "all the installation information was formatting \n",
    "so, if you restart GPU session, you must reinstall all the library, when install library or file before closed session\n",
    "not Kernel restart only GPU session restart\n",
    "---\n",
    "and also follow this solution\n",
    "1. pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22e54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze >> requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69858e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd94eb05",
   "metadata": {},
   "source": [
    "### before Starting make a simple function \n",
    "#### this function use for working clock to parameter value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e0333",
   "metadata": {},
   "source": [
    "## CUDA load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc565c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else :\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7b9b3",
   "metadata": {},
   "source": [
    "## Dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43583334",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"iamtarun/python_code_instructions_18k_alpaca\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b185f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"iamtarun/python_code_instructions_18k_alpaca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d3e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd07d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-2b-it\"\n",
    "tokenizer_name = \"google/gemma-2b-it\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a2b17",
   "metadata": {},
   "source": [
    "## Checking Datasets Type and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cdd070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 18612\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6673cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18612, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a5be7d",
   "metadata": {},
   "source": [
    "### using dataset's train_test_split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc8d0838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285524b",
   "metadata": {},
   "source": [
    "## using sklearn.model_selection's train_test_split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07c0a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ce08b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sklearn = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a1decc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 18612\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235ee05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(ds_sklearn[\"train\"], test_size=.3, random_state=1832)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6080b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21dae9",
   "metadata": {},
   "source": [
    "## model & tokenizer load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d0f0204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78da1e2fe9649349e3283e8a044d799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                          token=access_token,\n",
    "                                          device_map=\"auto\",\n",
    "                                           torch_dtype=torch.float32,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b677c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name,\n",
    "                                         token=access_token,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         max_length=100,\n",
    "                                         )\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8936a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 22 07:10:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  CUDA GPU                       On  | 00000000:E3:00.0 Off |                    0 |\n",
      "| N/A   44C    P0              73W / 300W |  10024MiB / 81074MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937eb82",
   "metadata": {},
   "source": [
    "## processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f78c9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2858d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 13028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'prompt'],\n",
       "        num_rows: 5584\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc980f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ds[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ca2d79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d6b818c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ds[\"test\"]\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ad2302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    return tokenizer(row[\"instruction\"],row[\"input\"],row[\"output\"],row[\"prompt\"], return_tensors=\"pt\", truncation=True, padding=True, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d511fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "617ae889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f2c445f76b4102ba298b777854e31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/13028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1846301eb8f74fe4967a736ce3db9960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = ds.map(process,\n",
    "           num_proc = multiprocessing.cpu_count(),\n",
    "           load_from_cache_file=False,\n",
    "           batched=True)\n",
    "train_dataset = ds[\"train\"]\n",
    "test_dataset = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc59aa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 13028\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d930fe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'prompt', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5584\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92f0a8",
   "metadata": {},
   "source": [
    "## model & Trainer arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6755447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c05e8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./eval_results_4\",\n",
    "                                 num_train_epochs=3,\n",
    "                                 per_device_train_batch_size=2,\n",
    "                                 per_device_eval_batch_size=2,\n",
    "                                 weight_decay=0.01,\n",
    "                                 logging_dir=\"./eval_logs_4\",\n",
    "                                 logging_steps=500,\n",
    "                                 warmup_steps=300,\n",
    "                                 dataloader_num_workers=4,\n",
    "                                 eval_accumulation_steps=1,\n",
    "                                 gradient_accumulation_steps=2,\n",
    "                                 optim=\"adamw_torch\",\n",
    "                                 evaluation_strategy=\"steps\",\n",
    "                                 save_strategy=\"steps\",\n",
    "                                 do_eval=True,\n",
    "                                 load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e8e49ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75147005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35abdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metrix = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e63972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(eval_pred):\n",
    "    logit, labels =eval_pred\n",
    "    predict = np.argmax(logit, axis=-1)\n",
    "    return acc_metrix.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55d039f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(model,\n",
    "                       args=training_args,\n",
    "                       train_dataset=train_dataset,\n",
    "                       eval_dataset=test_dataset,\n",
    "                       tokenizer=tokenizer,\n",
    "                       compute_metrics=compute_matrix,\n",
    "#                        callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79bbbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrlfdnjs9839\u001b[0m (\u001b[33mlineworld\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/work/sLLM/wandb/run-20240422_071108-2lf43uoh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/lineworld/huggingface/runs/2lf43uoh\" target=\"_blank\">earnest-snowflake-46</a></strong> to <a href=\"https://wandb.ai/lineworld/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='9771' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 501/9771 02:44 < 50:59, 3.03 it/s, Epoch 0.15/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='2792' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 240/2792 48:14 < 8:35:06, 0.08 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "model_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf6901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0 (NGC 23.03/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
